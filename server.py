# server.py - Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª VTOØŒ Gemini Inpainting Ùˆ Remove Background
# =========================================================================================
# ===> Ù†Ø³Ø®Ù‡ ØªÙ…ÛŒØ² Ø´Ø¯Ù‡ import Ù‡Ø§ <===
from flask import Flask, request, jsonify
from flask_cors import CORS
import base64
from io import BytesIO
from PIL import Image
import os
import warnings
import json
import datetime
import requests 
from typing import Tuple, Optional, Any
import numpy as np
import cv2
# from rembg import remove  <-- Ø¯ÛŒÚ¯Ø± Ø¨Ù‡ Ø§ÛŒÙ† Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…

# ðŸš¨ ØªØ¹Ø±ÛŒÙ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Linter
GEMINI_AVAILABLE = False
genai = None
APIError = None

# ðŸš¨ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Gemini Ø¨Ù‡ ØµÙˆØ±Øª Ø´Ø±Ø·ÛŒ
try:
    from google import genai
    from google.genai.errors import APIError
    GEMINI_AVAILABLE = True
except ImportError:
    warnings.warn("Gemini libraries not found. Advanced Inpainting is disabled.")

app = Flask(__name__)
CORS(app) # ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ CORS Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø² Electron/Frontend

# <<<<<<<<<<<<<<< Ú©Ù„ Ø§ÛŒÙ† Ø¨Ù„Ø§Ú© Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø®Ø´ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ÙØ¹Ù„ÛŒ Ø®ÙˆØ¯ Ú©Ù†ÛŒØ¯ >>>>>>>>>>>>>>>

# =========================================================================================
# ********************** ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ØªØ¨Ø¯ÛŒÙ„ (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡) **********************
# =========================================================================================

def base64_to_pil(base64_string: str) -> Image.Image:
    """
    Ø±Ø´ØªÙ‡ Base64 Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª ØªØµÙˆÛŒØ± PIL (RGBA) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if ',' in base64_string:
        base64_string = base64_string.split(',')[-1]
    img_data = base64.b64decode(base64_string)
    return Image.open(BytesIO(img_data)).convert("RGBA")

def pil_to_base64(pil_img: Image.Image) -> str:
    """
    ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª ØªØµÙˆÛŒØ± PIL Ø±Ø§ Ø¨Ù‡ Ø±Ø´ØªÙ‡ Base64 (Ø¨Ø§ ÙØ±Ù…Øª PNG) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    buffered = BytesIO()
    pil_img.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def pil_to_cv2(pil_img: Image.Image) -> np.ndarray:
    """
    ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª ØªØµÙˆÛŒØ± PIL (RGBA) Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ OpenCV (BGRA) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGBA2BGRA)

def cv2_to_pil(cv_img: np.ndarray) -> Image.Image:
    """
    ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ OpenCV Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª ØªØµÙˆÛŒØ± PIL ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if len(cv_img.shape) == 3 and cv_img.shape[2] == 3:
        return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))
    elif len(cv_img.shape) == 3 and cv_img.shape[2] == 4:
        return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGRA2RGBA))
    return Image.fromarray(cv_img)

def base64_to_cv2(base64_string: str, with_alpha: bool = True) -> np.ndarray:
    """
    Ø±Ø´ØªÙ‡ Base64 Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§ Ø¨Ù‡ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ OpenCV ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    pil_img = base64_to_pil(base64_string)
    cv_img = pil_to_cv2(pil_img)
    if not with_alpha:
        return cv2.cvtColor(cv_img, cv2.COLOR_BGRA2BGR)
    return cv_img

def cv2_to_base64(img: np.ndarray) -> str:
    """
    ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ OpenCV Ø±Ø§ Ø¨Ù‡ Ø±Ø´ØªÙ‡ Base64 (Ø¨Ø§ ÙØ±Ù…Øª PNG) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    pil_img = cv2_to_pil(img)
    return pil_to_base64(pil_img)


# =========================================================================================
# ********************** Ù…Ù†Ø·Ù‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ØµÙ„ÛŒ VTO Ùˆ Gemini **********************
# =========================================================================================

def process_vto_advanced(bg_base64, model_base64, corners_ratio, opacity, use_ai_inpainting, color_swap_hue, brightness):
    background_img_bgr = base64_to_cv2(bg_base64, with_alpha=False) 
    model_img_bgra = base64_to_cv2(model_base64, with_alpha=True)
    if background_img_bgr is None or model_img_bgra is None:
        return None, "Error loading images."

    if brightness != 1.0:
        bgr_p = model_img_bgra[:, :, :3]
        alpha_p = model_img_bgra[:, :, 3]
        bgr_p = cv2.convertScaleAbs(bgr_p, alpha=brightness, beta=0)
        model_img_bgra = cv2.merge([bgr_p, alpha_p])

    h_bg, w_bg = background_img_bgr.shape[:2]
    h_model, w_model = model_img_bgra.shape[:2] 
    inpainted_bg_bgr = background_img_bgr.copy() 
    
    corners_px = np.int32([[c[0]*w_bg, c[1]*h_bg] for c in corners_ratio])
    
    # Gemini Inpainting
    if GEMINI_CLIENT_READY and use_ai_inpainting: 
        try:
            mask = np.zeros((h_bg, w_bg), dtype=np.uint8)
            cv2.fillPoly(mask, [corners_px], 255) 
            bg_pil = cv2_to_pil(background_img_bgr) 
            mask_pil = Image.fromarray(mask).convert('L') 
            
            response = GEMINI_CLIENT.models.generate_images( 
                model='imagen-3.0-generate-002', 
                prompt="Remove the object in the masked area and inpaint smoothly.",
                config={"number_of_images": 1, "output_mime_type": "image/jpeg"},
                image=bg_pil, mask_image=mask_pil 
            )
            if response.generated_images:
                inpainted_bg_rgb = np.array(response.generated_images[0].image.convert("RGB")) 
                inpainted_bg_bgr = cv2.cvtColor(inpainted_bg_rgb, cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"Gemini Error: {e}")

    # Homography
    pts_model = np.float32([[0, 0], [w_model-1, 0], [w_model-1, h_model-1], [0, h_model-1]])
    pts_target = np.float32(corners_px)
    M = cv2.getPerspectiveTransform(pts_model, pts_target) 
    warped_model = cv2.warpPerspective(model_img_bgra, M, (w_bg, h_bg))

    # Blending
    alpha_channel = (warped_model[:, :, 3].astype(np.float32) / 255.0) * opacity
    overlay_colors = warped_model[:, :, :3]
    final_result = inpainted_bg_bgr.copy().astype(np.float32) 
    
    for c in range(3):
        final_result[:,:,c] = (alpha_channel * overlay_colors[:,:,c] + (1 - alpha_channel) * final_result[:,:,c])
    
    return np.uint8(final_result), None

# =========================================================================================
# ********************** ØªÙ†Ø¸ÛŒÙ…Ø§Øª Gemini **********************
# =========================================================================================

GEMINI_API_KEY = "AIzaSyA7x8Po9-CCqD_OIQCKJzeYIosRZnQ6NTk" 
GEMINI_CLIENT = None
GEMINI_CLIENT_READY = False

if GEMINI_AVAILABLE and GEMINI_API_KEY:
    try:
        GEMINI_CLIENT = genai.Client(api_key=GEMINI_API_KEY)
        GEMINI_CLIENT_READY = True
        print("Gemini Client successfully initialized.")
    except Exception as e:
        print(f"Gemini initialization failed: {e}")

# =========================================================================================
# ********************** ØªØ¹Ø±ÛŒÙ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ API **********************
# =========================================================================================

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "ok", "gemini_ready": GEMINI_CLIENT_READY}), 200

@app.route('/api/vto/process', methods=['POST'])
def process_image_api():
    try:
        data = request.json
        result_img, error = process_vto_advanced(
            data.get('background'), data.get('model'), data.get('corners'), 
            data.get('opacity', 1.0), data.get('use_ai_inpainting', False), 
            data.get('color_swap_hue'), data.get('brightness', 1.0)
        )
        if error: return jsonify({"error": error}), 500
        return jsonify({"status": "success", "result_image_base64": cv2_to_base64(result_img)})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# =======================================================
# ===> Ù…Ø³ÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ: Ø§Ø¬Ø±Ø§ÛŒ GrabCut Ø¨Ø§ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª <===
# =======================================================
@app.route('/api/grabcut', methods=['POST'])
def grabcut_api():
    try:
        data = request.json
        image_data_base64 = data['image']
        
        img_bytes = base64.b64decode(image_data_base64.split(',')[1])
        img_np = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)

        if img is None:
            raise ValueError("Could not decode image.")

        # Ø³Ø§Ø®Øª Ù…Ø§Ø³Ú© Ø§ÙˆÙ„ÛŒÙ‡
        mask = np.zeros(img.shape[:2], np.uint8)
        bgdModel = np.zeros((1, 65), np.float64)
        fgdModel = np.zeros((1, 65), np.float64)
        
        # Û±. Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ú©Ø§Ø¯Ø±
        rect_data = data['rect']
        rect = (rect_data['x'], rect_data['y'], rect_data['w'], rect_data['h'])
        cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
        
        # Û². Ø§Ø¹Ù…Ø§Ù„ Ù†Ù‚Ø§Ø· Ø§ØµÙ„Ø§Ø­ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)
        refine_points = data.get('refine_points', [])
        if refine_points:
            for point in refine_points:
                color = cv2.GC_FGD if point['mode'] == 'fg' else cv2.GC_BGD
                cv2.circle(mask, (point['x'], point['y']), 5, color, -1)
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ù…Ø§Ø³Ú© Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡
            cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)

        # Û³. Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø´ÙØ§Ù
        final_mask = np.where((mask == cv2.GC_PR_FGD) | (mask == cv2.GC_FGD), 255, 0).astype('uint8')
        final_mask = cv2.GaussianBlur(final_mask, (3, 3), 0)
        
        b, g, r = cv2.split(img)
        result_rgba = cv2.merge((b, g, r, final_mask))

        # Û´. Ø¨Ø±Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ (Auto-Cropping)
        contours, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            main_contour = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(main_contour)
            cropped_result = result_rgba[y:y+h, x:x+w]
        else:
            cropped_result = result_rgba

        _, buffer = cv2.imencode('.png', cropped_result)
        output_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return jsonify({ "status": "success", "image": f"data:image/png;base64,{output_base64}" })

    except Exception as e:
        print(f"Error in GrabCut API: {e}")
        return jsonify({"error": str(e)}), 500

# =========================================================================
if __name__ == '__main__':
    print("Starting AI Service (Python Flask)...")
    app.run(host='127.0.0.1', port=5000, debug=False)
